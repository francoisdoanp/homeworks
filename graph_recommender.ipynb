{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graph-recommender.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZWqQ01EN-fyc",
        "L67hJRkqH5t1",
        "ZrIh1nqWKS_H",
        "dr3ROhet3eMg"
      ],
      "authorship_tag": "ABX9TyML4C57licmZXA7unG7MUh4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francoisdoanp/projects/blob/master/graph_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftJyxVHw8ijX",
        "colab_type": "text"
      },
      "source": [
        "# Link prediction for Steam dataset\n",
        "\n",
        "Our goal is to predict games for a recommender system based on link prediction on graphs. We use the Steam 200k users dataset [available here](https://www.kaggle.com/tamber/steam-video-games/version/1) as well as games information to supplement our node features, available [here](https://www.kaggle.com/nikdavis/steam-store-games#steam.csv)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM_RmhFY8m_e",
        "colab_type": "text"
      },
      "source": [
        "## Installs & Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tEMbuUA8fiF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b678bd72-486b-499c-b120-0b53bbec5a58"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install stellargraph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stellargraph\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/f8/91a0f8597064b3084f57f314273f10d214b5cfa34cc03a83af981dc32f65/stellargraph-0.11.1-py3-none-any.whl (348kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from stellargraph) (3.6.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from stellargraph) (1.4.1)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from stellargraph) (2.2.0rc3)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from stellargraph) (1.18.3)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from stellargraph) (1.0.3)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.6/dist-packages (from stellargraph) (3.2.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.6/dist-packages (from stellargraph) (2.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from stellargraph) (0.22.2.post1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->stellargraph) (1.12.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->stellargraph) (1.11.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (3.2.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.10.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.2.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (2.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.6.3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (1.28.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1.0->stellargraph) (0.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->stellargraph) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->stellargraph) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->stellargraph) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->stellargraph) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->stellargraph) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.2->stellargraph) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->stellargraph) (0.14.1)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->stellargraph) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->stellargraph) (1.12.46)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->stellargraph) (2.21.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow>=2.1.0->stellargraph) (46.1.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->stellargraph) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->stellargraph) (1.7.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->stellargraph) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->stellargraph) (1.6.0.post3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->stellargraph) (3.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->stellargraph) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->stellargraph) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.46 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->stellargraph) (1.15.46)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.4.0->stellargraph) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.4.0->stellargraph) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.4.0->stellargraph) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.4.0->stellargraph) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->stellargraph) (1.3.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->stellargraph) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->stellargraph) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->stellargraph) (0.2.8)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->smart-open>=1.2.1->gensim>=3.4.0->stellargraph) (0.15.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->stellargraph) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->stellargraph) (0.4.8)\n",
            "Installing collected packages: stellargraph\n",
            "Successfully installed stellargraph-0.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eUWSHf68rNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import stellargraph as sg\n",
        "from stellargraph.mapper import HinSAGELinkGenerator\n",
        "from stellargraph.layer import HinSAGE, link_regression, link_classification\n",
        "from tensorflow.keras import Model, optimizers, losses, metrics\n",
        "import tensorflow.keras.backend as K\n",
        "from stellargraph.data import EdgeSplitter, BiasedRandomWalk\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from sklearn import model_selection, preprocessing\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "import multiprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U-ZckEO8tGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tftcAbME8uYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# User CSV file link\n",
        "linku = 'https://drive.google.com/open?id=1v4bZDymvxhXz9K8bt6QdUFltqUycwV1i'\n",
        "_ , idu = linku.split('=')\n",
        "# Games CSV file link\n",
        "linkg = 'https://drive.google.com/open?id=1Aj105y410QmR7uZFoTyh8BAIpfAoNk87'\n",
        "_ , idg = linkg.split('=')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrYZyj_d8v3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dlu = drive.CreateFile({'id':idu}) \n",
        "dlu.GetContentFile('steam-200k.csv')  \n",
        "temp_users = pd.read_csv('steam-200k.csv', header=None, usecols=[0,1,2,3], names=['userID', 'gameTitle', 'behavior', 'value'])\n",
        "temp_users.userID = 'u' + temp_users.userID.astype(str)\n",
        "\n",
        "dlg = drive.CreateFile({'id':idg}) \n",
        "dlg.GetContentFile('steam.csv')  \n",
        "temp_games = pd.read_csv('steam.csv')\n",
        "temp_games.appid = 'g' + temp_games.appid.astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF4M72yw8xk7",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knHdNDP68z_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f00c3ef1-99d9-41d7-db8b-875e9956e830"
      },
      "source": [
        "# Modifying game titles so as to match the most games possibles\n",
        "\n",
        "temp_users['gameTitle'] = temp_users.gameTitle.str.lower()\n",
        "temp_users['gameTitle'] = temp_users.gameTitle.str.replace(r'\\W+', ' ').replace('\\s+', ' ', regex=True)\n",
        "temp_games['name'] = temp_games.name.str.lower()\n",
        "temp_games['name'] = temp_games.name.str.replace(r'\\W+', ' ').replace('\\s+', ' ', regex=True)\n",
        "\n",
        "# Removing games from games_df that are not in the user interaction dataset and vice versa\n",
        "games_df = temp_games[temp_games.name.isin(temp_users.gameTitle)]\n",
        "userst = temp_users[temp_users.gameTitle.isin(temp_games.name)]\n",
        "\n",
        "# From these outputs, we see that we lost quite a few interactions (from 200k to 51 330)\n",
        "print(games_df.name.nunique())\n",
        "print(userst.gameTitle.nunique())\n",
        "print(userst.userID.nunique())\n",
        "print(userst.shape)\n",
        "print(games_df.shape)\n",
        "\n",
        "# There also seems to be duplicate games in our dataset. We will only keep the first observation.\n",
        "games = games_df.drop_duplicates(subset=['name'])\n",
        "print(games.duplicated(subset=['name']).any())\n",
        "print(games.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3057\n",
            "3057\n",
            "11369\n",
            "(135163, 4)\n",
            "(3066, 18)\n",
            "False\n",
            "(3057, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi1WBu2u9mY9",
        "colab_type": "text"
      },
      "source": [
        "### Building game features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmEY78Xz9yra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7e05ca00-262c-4432-c4a1-96633f2ad0f0"
      },
      "source": [
        "#########################\n",
        "# WITH LESS FEATURES\n",
        "\n",
        "# Adding dummies for the owners variable in the games df\n",
        "games = pd.concat([games, games['owners'].str.get_dummies()], axis=1)\n",
        "\n",
        "# The developper, publisher, platforms, categories, genres, steamspy_tags columns all contain\n",
        "# semicolons as separators when there are multiple entries. We need to transform those to dummies\n",
        "mult = ['developer', 'publisher', 'platforms', 'categories', 'genres', 'steamspy_tags']\n",
        "\n",
        "tempg = games\n",
        "\n",
        "for col in mult:\n",
        "  games = pd.concat([games, tempg[col].str.get_dummies(sep=';')], axis=1)\n",
        "\n",
        "# Dropping columns with the same name, which leads to a restricted number of features\n",
        "games.drop(mult, axis=1, inplace=True)\n",
        "print(games.shape)\n",
        "games = games.loc[:, ~games.columns.duplicated()]\n",
        "games.drop([' ', '(none)'], axis=1, inplace=True)\n",
        "print(games.shape)\n",
        "\n",
        "\n",
        "# We also need to change to format of the date variable. Here, we will extract year and month.\n",
        "\n",
        "games['year'] = pd.DatetimeIndex(games['release_date']).year\n",
        "games['month'] = pd.DatetimeIndex(games['release_date']).month "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3057, 3986)\n",
            "(3057, 2827)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPvApHLeA9MF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building dictionnary of game id's and titles\n",
        "games_dict = games.set_index('name').to_dict()['appid']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTi6U_XAYwXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9b0858a5-f185-4979-aa1f-b9ec6dd7582e"
      },
      "source": [
        "#########################\n",
        "# WITH EVEN LESS FEATURES\n",
        "\n",
        "# Adding dummies for the owners variable in the games df\n",
        "games = pd.concat([games, games['owners'].str.get_dummies()], axis=1)\n",
        "\n",
        "# The developper, publisher, platforms, categories, genres, steamspy_tags columns all contain\n",
        "# semicolons as separators when there are multiple entries. We need to transform those to dummies\n",
        "mult = ['developer', 'publisher', 'platforms', 'categories', 'genres', 'steamspy_tags']\n",
        "\n",
        "tempg = games\n",
        "\n",
        "for col in mult:\n",
        "  games = pd.concat([games, tempg[col].str.get_dummies(sep=';')], axis=1)\n",
        "\n",
        "# Dropping columns with the same name, which leads to a restricted number of features\n",
        "games.drop(mult, axis=1, inplace=True)\n",
        "print(games.shape)\n",
        "games = games.loc[:, ~games.columns.duplicated()]\n",
        "games.drop([' ', '(none)'], axis=1, inplace=True)\n",
        "print(games.shape)\n",
        "\n",
        "games.drop([col for col, val in games.iloc[:,12::].sum().iteritems() if val < 10], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# We also need to change to format of the date variable. Here, we will extract year and month.\n",
        "\n",
        "games['year'] = pd.DatetimeIndex(games['release_date']).year\n",
        "games['month'] = pd.DatetimeIndex(games['release_date']).month \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3057, 3986)\n",
            "(3057, 2827)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xFF03Tn9oq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "# This code is for FULL FEATURES, which leads to about 3500 variables. We used a restricted dataset\n",
        "\n",
        "# Adding dummies for the owners variable in the games df\n",
        "games = pd.concat([games, games['owners'].str.get_dummies()], axis=1)\n",
        "\n",
        "# The developper, publisher, platforms, categories, genres, steamspy_tags columns all contain\n",
        "# semicolons as separators when there are multiple entries. We need to transform those to dummies\n",
        "\n",
        "mult = ['developer', 'publisher', 'platforms', 'categories', 'genres', 'steamspy_tags']\n",
        "prefix = ['d_', 'p_', 'pl_', 'cat_', 'gen_', 'ss_']\n",
        "\n",
        "tempg = games\n",
        "\n",
        "for col,pf in zip(mult, prefix):\n",
        "  games = pd.concat([games, tempg[col].str.get_dummies(sep=';').add_prefix(pf)], axis=1)\n",
        "\n",
        "games.drop(mult, axis=1, inplace=True)\n",
        "\n",
        "# We also need to change to format of the date variable. Here, we will extract year and month.\n",
        "\n",
        "games['year'] = pd.DatetimeIndex(games['release_date']).year\n",
        "games['month'] = pd.DatetimeIndex(games['release_date']).month\n",
        "\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLOeHCnm-Fe-",
        "colab_type": "text"
      },
      "source": [
        "### Building user features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQnZR-0s-D43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For the users, we feel we can perhaps extract features such as:\n",
        "# - Number of purchases\n",
        "# - Total playtime\n",
        "#\n",
        "# These will be taken from the original data, disregarding whether we have the games in question in our dataset or not\n",
        "\n",
        "n_purchases = temp_users[temp_users['behavior'] == 'purchase'].groupby(['userID'])['value'].sum()\n",
        "n_playtime = temp_users[temp_users['behavior'] == 'play'].groupby(['userID'])['value'].sum()\n",
        "\n",
        "users = pd.merge(n_purchases, n_playtime, left_on='userID', right_on='userID', how='left').reset_index().rename(columns={'value_x' : 'nPurchases', 'value_y':'totalPlaytime'}).fillna(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWqQ01EN-fyc",
        "colab_type": "text"
      },
      "source": [
        "## Model 1: Link prediction with playtime as weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85NtHXS8-84Q",
        "colab_type": "text"
      },
      "source": [
        "### Data preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K63dBYF--8DP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc87e6e-2d7b-44d4-ecc3-f2320ceab8e4"
      },
      "source": [
        "# Removing purchase observations\n",
        "temp_u = userst[userst.behavior == 'play']\n",
        "\n",
        "# Building user dataframe with retained users\n",
        "uniqueu_w = temp_u.userID.unique()\n",
        "users_w = users[users.userID.isin(uniqueu_w)]\n",
        "users_w.set_index('userID', inplace=True)\n",
        "\n",
        "# Building game dataframe with retained games\n",
        "uniqueg_w = temp_u.gameTitle.unique()\n",
        "games_w = games[games.name.isin(uniqueg_w)]\n",
        "\n",
        "# Dropping columns we will not be using from games dataframe\n",
        "games_w.drop(['release_date', 'owners', 'name'], axis=1, inplace=True)\n",
        "games_w.set_index('appid', inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMcLbMj6Anx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061fac69-7261-49bc-f784-cdee24a55457"
      },
      "source": [
        "# Normalizing values\n",
        "users_w[['nPurchases', 'totalPlaytime']] = scaler.fit_transform(users_w[['nPurchases', 'totalPlaytime']])\n",
        "games_w[['positive_ratings', 'negative_ratings', 'average_playtime', 'median_playtime', 'price', 'year', 'month', 'required_age', 'achievements']] = scaler.fit_transform(games_w[['positive_ratings', 'negative_ratings', 'average_playtime', 'median_playtime', 'price', 'year', 'month', 'required_age', 'achievements']])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:2969: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:2935: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_array(key, value)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGoheIco-5B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building edgelist\n",
        "\n",
        "edgelist_w = temp_u.reset_index().drop(['behavior', 'index'], axis=1)\n",
        "edgelist_w.replace({'gameTitle' : games_dict}, inplace=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-ZzEX1NBOOP",
        "colab_type": "text"
      },
      "source": [
        "### Final data exploration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwZdWrz7BQQY",
        "colab_type": "text"
      },
      "source": [
        "### Building Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4ndJB8lBVNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building graph\n",
        "\n",
        "graph_w = sg.StellarGraph({'users': users_w, 'games': games_w}, \n",
        "                        {'play': edgelist_w[['userID', 'gameTitle']]},\n",
        "                        source_column='userID',\n",
        "                        target_column='gameTitle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLL8XRMnzhkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4db244-053a-4d66-c5bc-27ef4c2fd8e4"
      },
      "source": [
        "print(graph_w.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StellarDiGraph: Directed multigraph\n",
            " Nodes: 12908, Edges: 51330\n",
            "\n",
            " Node types:\n",
            "  users: [10492]\n",
            "    Features: float32 vector, length 2\n",
            "    Edge types: users-play->games\n",
            "  games: [2416]\n",
            "    Features: float32 vector, length 2825\n",
            "    Edge types: none\n",
            "\n",
            " Edge types:\n",
            "    users-play->games: [51330]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxs3Jf49Bcif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train test split\n",
        "\n",
        "edges_train_w, edges_test_w = model_selection.train_test_split(edgelist_w, train_size=0.8, test_size=0.2)\n",
        "edgelist_train_w = list(edges_train_w[['userID', 'gameTitle']].itertuples(index=False))\n",
        "edgelist_test_w = list(edges_test_w[['userID', 'gameTitle']].itertuples(index=False))\n",
        "\n",
        "labels_train_w = edges_train_w[\"value\"]\n",
        "labels_test_w = edges_test_w[\"value\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3DDv44mBoNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d1c063-3842-4aea-a7ce-552952607765"
      },
      "source": [
        "# Parameters\n",
        "\n",
        "batch_size_w = 50\n",
        "epochs_w = 50\n",
        "num_samples_w = [20,10]\n",
        "hinsage_layer_w = [256,256]\n",
        "num_workers_w = multiprocessing.cpu_count()\n",
        "\n",
        "generator_w = HinSAGELinkGenerator(graph_w, batch_size_w, num_samples_w, head_node_types=['users', 'games'])\n",
        "train_gen_w = generator_w.flow(edgelist_train_w, labels_train_w, shuffle=True)\n",
        "test_gen_w = generator_w.flow(edgelist_test_w, labels_test_w)\n",
        "\n",
        "assert len(hinsage_layer_w) == len(num_samples_w)\n",
        "\n",
        "hinsage_w = HinSAGE(layer_sizes=hinsage_layer_w, generator=generator_w, bias=True)\n",
        "\n",
        "x_inw, x_outw = hinsage_w.in_out_tensors()\n",
        "pred_w = link_regression(edge_embedding_method=\"concat\")(x_outw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-a106fc149233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhinsage_layer_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhinsage_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHinSAGE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhinsage_layer_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mx_inw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_outw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhinsage_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_out_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stellargraph/layer/hinsage.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer_sizes, generator, aggregator, bias, dropout, normalize, activations, kernel_initializer, kernel_regularizer, kernel_constraint, bias_initializer, bias_regularizer, bias_constraint, n_samples, input_neighbor_tree, input_dim, multiplicity)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtree_schema\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneigh_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dims\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         ]\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stellargraph/layer/hinsage.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtree_schema\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneigh_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dims\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         ]\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wqTQvP4CAP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining loss function\n",
        "\n",
        "def root_mean_square_error(s_true, s_pred):\n",
        "    return K.sqrt(K.mean(K.pow(s_true - s_pred, 2)))\n",
        "\n",
        "# Building model\n",
        "\n",
        "model_w = Model(inputs=x_inw, outputs=pred_w)\n",
        "model_w.compile(\n",
        "    optimizer=optimizers.Adam(lr=0.1),\n",
        "    loss=losses.mean_squared_error,\n",
        "    metrics=[root_mean_square_error, metrics.mae],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEcxeVMsCNAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_w = model_w.fit(\n",
        "    train_gen_w,\n",
        "    validation_data=test_gen_w,\n",
        "    epochs=epochs_w,\n",
        "    verbose=1,\n",
        "    shuffle=False,\n",
        "    use_multiprocessing=False,\n",
        "    workers=num_workers_w,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L67hJRkqH5t1",
        "colab_type": "text"
      },
      "source": [
        "## Model 2: Restricted data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrIh1nqWKS_H",
        "colab_type": "text"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvzriFPkIBck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keeping only purchases\n",
        "\n",
        "temp_ur = userst[userst.behavior == 'play']\n",
        "\n",
        "# Building user dataframe with retained users\n",
        "uniqueu_r = temp_ur.userID.unique()\n",
        "users_r =  users[users.userID.isin(uniqueu_r)]\n",
        "users_r.set_index('userID', inplace=True)\n",
        "\n",
        "# Building game dataframe with retained games\n",
        "uniqueg_r = temp_ur.gameTitle.unique()\n",
        "games_r = games[games.name.isin(uniqueg_r)]\n",
        "\n",
        "# Dropping columns we will not be using from games dataframe\n",
        "games_r.drop(['release_date', 'owners', 'name'], axis=1, inplace=True)\n",
        "games_r.set_index('appid', inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIgLfoYCJ6cW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizing values\n",
        "users_r[['nPurchases', 'totalPlaytime']] = scaler.fit_transform(users_r[['nPurchases', 'totalPlaytime']])\n",
        "games_r[['positive_ratings', 'negative_ratings', 'average_playtime', 'median_playtime', 'price', 'year', 'month', 'required_age', 'achievements']] = scaler.fit_transform(games_r[['positive_ratings', 'negative_ratings', 'average_playtime', 'median_playtime', 'price', 'year', 'month', 'required_age', 'achievements']])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0jpuR0rJ9WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building edgelist\n",
        "\n",
        "edgelist_r = temp_ur.reset_index().drop(['behavior', 'index'], axis=1)\n",
        "edgelist_r.replace({'gameTitle' : games_dict}, inplace=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kfyy_ot5scw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing games or users that have less than 5 occurence in our edgelist\n",
        "v = edgelist_r[['userID', 'gameTitle']]\n",
        "edgelist_reduced = edgelist_r[v.replace(v.stack().value_counts()).gt(5).all(1)].reset_index(drop=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcF6wEVb6LCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u_g = edgelist_reduced.gameTitle.unique()\n",
        "u_u = edgelist_reduced.userID.unique()\n",
        "\n",
        "games_reduced = games_r[games_r.index.isin(u_g)]\n",
        "users_reduced = users_r[users_r.index.isin(u_u)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9novAGI-KUtD",
        "colab_type": "text"
      },
      "source": [
        "### Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AzJSN2PKWEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph_b = sg.StellarGraph({'users': users_reduced, 'games': games_reduced}, \n",
        "                        {'play': edgelist_reduced[['userID', 'gameTitle']]},\n",
        "                        source_column='userID',\n",
        "                        target_column='gameTitle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KDmCXxMKfmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train test split\n",
        "\n",
        "edges_train_r, edges_test_r = model_selection.train_test_split(edgelist_reduced, train_size=0.8, test_size=0.2)\n",
        "edgelist_train_r = list(edges_train_r[['userID', 'gameTitle']].itertuples(index=False))\n",
        "edgelist_test_r = list(edges_test_r[['userID', 'gameTitle']].itertuples(index=False))\n",
        "\n",
        "labels_train_r = edges_train_r[\"value\"]\n",
        "labels_test_r = edges_test_r[\"value\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV_8ZozuLLLw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f150184-cec6-4724-a004-72ad30905b8e"
      },
      "source": [
        "# Parameters\n",
        "\n",
        "batch_size_r = 50\n",
        "epochs_r = 50\n",
        "num_samples_r = [20,10]\n",
        "hinsage_layer_r = [256,256]\n",
        "num_workers_r = multiprocessing.cpu_count()\n",
        "\n",
        "generator_r = HinSAGELinkGenerator(graph_b, batch_size_r, num_samples_r, head_node_types=['users', 'games'])\n",
        "train_gen_r = generator_r.flow(edgelist_train_r, labels_train_r, shuffle=True)\n",
        "test_gen_r = generator_r.flow(edgelist_test_r, labels_test_r)\n",
        "\n",
        "hinsage_r = HinSAGE(layer_sizes=hinsage_layer_r, generator=generator_r, bias=True)\n",
        "\n",
        "x_inr, x_outr = hinsage_r.in_out_tensors()\n",
        "pred_r = link_regression(edge_embedding_method=\"concat\")(x_outr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "link_regression: using 'concat' method to combine node embeddings into edge embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2d3ua3T9na_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining loss function\n",
        "\n",
        "def root_mean_square_error(s_true, s_pred):\n",
        "    return K.sqrt(K.mean(K.pow(s_true - s_pred, 2)))\n",
        "\n",
        "# Building model\n",
        "\n",
        "model_r = Model(inputs=x_inr, outputs=pred_r)\n",
        "model_r.compile(\n",
        "    optimizer=optimizers.Adam(lr=0.1),\n",
        "    loss=losses.mean_squared_error,\n",
        "    metrics=[root_mean_square_error, metrics.mae],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2apoYlEkMf14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072744f6-9af0-4a01-fe5f-fc5673c155d9"
      },
      "source": [
        "history_r = model_r.fit(\n",
        "    train_gen_r,\n",
        "    validation_data=test_gen_r,\n",
        "    epochs=epochs_r,\n",
        "    verbose=1,\n",
        "    shuffle=False,\n",
        "    use_multiprocessing=False,\n",
        "    workers=num_workers_r,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "566/566 [==============================] - 150s 264ms/step - loss: 40286.8750 - root_mean_square_error: 150.0392 - mean_absolute_error: 59.4625 - val_loss: 26583.4609 - val_root_mean_square_error: 131.5465 - val_mean_absolute_error: 58.2906\n",
            "Epoch 2/50\n",
            "566/566 [==============================] - 146s 259ms/step - loss: 37560.9219 - root_mean_square_error: 149.8055 - mean_absolute_error: 62.9931 - val_loss: 25979.1738 - val_root_mean_square_error: 128.8490 - val_mean_absolute_error: 54.0834\n",
            "Epoch 3/50\n",
            "566/566 [==============================] - 146s 259ms/step - loss: 37042.3320 - root_mean_square_error: 152.1078 - mean_absolute_error: 63.8470 - val_loss: 25933.9297 - val_root_mean_square_error: 134.2472 - val_mean_absolute_error: 59.6988\n",
            "Epoch 4/50\n",
            "566/566 [==============================] - 146s 259ms/step - loss: 36874.8047 - root_mean_square_error: 151.8592 - mean_absolute_error: 64.4924 - val_loss: 26661.0801 - val_root_mean_square_error: 139.0616 - val_mean_absolute_error: 66.5500\n",
            "Epoch 5/50\n",
            "566/566 [==============================] - 146s 257ms/step - loss: 36673.4805 - root_mean_square_error: 153.1605 - mean_absolute_error: 64.4380 - val_loss: 25857.0625 - val_root_mean_square_error: 131.4902 - val_mean_absolute_error: 58.3833\n",
            "Epoch 6/50\n",
            "566/566 [==============================] - 146s 257ms/step - loss: 36560.3828 - root_mean_square_error: 152.2626 - mean_absolute_error: 64.5126 - val_loss: 26310.9609 - val_root_mean_square_error: 137.2319 - val_mean_absolute_error: 63.7151\n",
            "Epoch 7/50\n",
            "566/566 [==============================] - 145s 256ms/step - loss: 36580.8984 - root_mean_square_error: 153.3651 - mean_absolute_error: 65.5229 - val_loss: 26063.8711 - val_root_mean_square_error: 133.2723 - val_mean_absolute_error: 55.6397\n",
            "Epoch 8/50\n",
            "566/566 [==============================] - 145s 257ms/step - loss: 36367.0781 - root_mean_square_error: 154.2011 - mean_absolute_error: 64.7066 - val_loss: 26278.4961 - val_root_mean_square_error: 135.6451 - val_mean_absolute_error: 60.6862\n",
            "Epoch 9/50\n",
            "566/566 [==============================] - 146s 258ms/step - loss: 36502.1719 - root_mean_square_error: 150.9233 - mean_absolute_error: 65.0576 - val_loss: 26686.4199 - val_root_mean_square_error: 139.3110 - val_mean_absolute_error: 64.5029\n",
            "Epoch 10/50\n",
            "566/566 [==============================] - 148s 262ms/step - loss: 36433.1914 - root_mean_square_error: 153.8388 - mean_absolute_error: 65.5488 - val_loss: 26932.3633 - val_root_mean_square_error: 139.7511 - val_mean_absolute_error: 62.4849\n",
            "Epoch 11/50\n",
            "566/566 [==============================] - 147s 260ms/step - loss: 36397.5430 - root_mean_square_error: 152.7209 - mean_absolute_error: 65.3558 - val_loss: 26258.3535 - val_root_mean_square_error: 135.8202 - val_mean_absolute_error: 61.2441\n",
            "Epoch 12/50\n",
            "566/566 [==============================] - 145s 257ms/step - loss: 36345.6523 - root_mean_square_error: 153.7699 - mean_absolute_error: 65.4258 - val_loss: 26388.0176 - val_root_mean_square_error: 135.7069 - val_mean_absolute_error: 60.2223\n",
            "Epoch 13/50\n",
            "566/566 [==============================] - 144s 255ms/step - loss: 36166.8672 - root_mean_square_error: 152.4177 - mean_absolute_error: 64.5363 - val_loss: 27257.2891 - val_root_mean_square_error: 142.6574 - val_mean_absolute_error: 66.7056\n",
            "Epoch 14/50\n",
            "566/566 [==============================] - 144s 255ms/step - loss: 36294.8516 - root_mean_square_error: 153.4666 - mean_absolute_error: 65.7316 - val_loss: 26732.1660 - val_root_mean_square_error: 137.8921 - val_mean_absolute_error: 62.9336\n",
            "Epoch 15/50\n",
            "566/566 [==============================] - 145s 256ms/step - loss: 36165.9102 - root_mean_square_error: 153.4299 - mean_absolute_error: 64.9282 - val_loss: 26729.0625 - val_root_mean_square_error: 138.1074 - val_mean_absolute_error: 63.4831\n",
            "Epoch 16/50\n",
            "566/566 [==============================] - 146s 257ms/step - loss: 36173.2266 - root_mean_square_error: 152.1804 - mean_absolute_error: 65.0747 - val_loss: 27438.8496 - val_root_mean_square_error: 143.6829 - val_mean_absolute_error: 68.2709\n",
            "Epoch 17/50\n",
            "566/566 [==============================] - 146s 258ms/step - loss: 36199.3164 - root_mean_square_error: 153.1372 - mean_absolute_error: 65.1032 - val_loss: 26488.9219 - val_root_mean_square_error: 135.6667 - val_mean_absolute_error: 61.7858\n",
            "Epoch 18/50\n",
            "566/566 [==============================] - 146s 258ms/step - loss: 36153.7852 - root_mean_square_error: 153.9025 - mean_absolute_error: 65.5280 - val_loss: 27047.3496 - val_root_mean_square_error: 139.4380 - val_mean_absolute_error: 63.3963\n",
            "Epoch 19/50\n",
            "566/566 [==============================] - 146s 258ms/step - loss: 36141.9961 - root_mean_square_error: 153.9182 - mean_absolute_error: 65.5511 - val_loss: 27060.6113 - val_root_mean_square_error: 141.5057 - val_mean_absolute_error: 64.6504\n",
            "Epoch 20/50\n",
            "566/566 [==============================] - 147s 259ms/step - loss: 35990.1289 - root_mean_square_error: 153.2290 - mean_absolute_error: 65.2200 - val_loss: 26772.3574 - val_root_mean_square_error: 138.2273 - val_mean_absolute_error: 62.2323\n",
            "Epoch 21/50\n",
            "566/566 [==============================] - 148s 262ms/step - loss: 36080.0391 - root_mean_square_error: 154.0056 - mean_absolute_error: 65.5196 - val_loss: 27256.5762 - val_root_mean_square_error: 140.0639 - val_mean_absolute_error: 63.2938\n",
            "Epoch 22/50\n",
            "566/566 [==============================] - ETA: 0s - loss: 35966.0195 - root_mean_square_error: 153.0407 - mean_absolute_error: 65.7739"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-67-0c4235456590>\", line 8, in <module>\n",
            "    workers=num_workers_r,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 875, in fit\n",
            "    return_dict=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 66, in _method_wrapper\n",
            "    return method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1084, in evaluate\n",
            "    tmp_logs = test_function(iterator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 618, in _call\n",
            "    results = self._stateful_fn(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\n",
            "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1665, in _filtered_call\n",
            "    self.captured_inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 1746, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 598, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w66AXXuRK-8E",
        "colab_type": "text"
      },
      "source": [
        "## Model 3: Binary link prediction\n",
        "\n",
        "Keeping only observations for purchases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDfO2SPpLEVL",
        "colab_type": "text"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eSapI-HLDs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keeping only purchases\n",
        "\n",
        "temp_ub = userst[userst.behavior == 'purchase']\n",
        "\n",
        "# Building user dataframe with retained users\n",
        "uniqueu_b = temp_ub.userID.unique()\n",
        "users_b =  users[users.userID.isin(uniqueu_b)]\n",
        "users_b.set_index('userID', inplace=True)\n",
        "\n",
        "# Building game dataframe with retained games\n",
        "uniqueg_b = temp_ub.gameTitle.unique()\n",
        "games_b = games[games.name.isin(uniqueg_b)]\n",
        "\n",
        "# Dropping columns we will not be using from games dataframe\n",
        "games_b.drop(['release_date', 'owners', 'name'], axis=1, inplace=True)\n",
        "games_list = games_b[['appid']]\n",
        "games_b.set_index('appid', inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ3GnmyqLJc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "355cdcb2-010d-4ca8-83e7-aaef407af4f8"
      },
      "source": [
        "# Normalizing values\n",
        "users_b[['nPurchases', 'totalPlaytime']] = scaler.fit_transform(users_b[['nPurchases', 'totalPlaytime']])\n",
        "games_b[['positive_ratings', 'negative_ratings', 'average_playtime', 'median_playtime', 'price', 'year', 'month', 'required_age', 'achievements']] = scaler.fit_transform(games_b[['positive_ratings', 'negative_ratings', 'average_playtime', 'median_playtime', 'price', 'year', 'month', 'required_age', 'achievements']])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:2969: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:2935: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_array(key, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OayQumdJLLBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building edgelist\n",
        "edgelist_b = temp_ub.drop(['behavior', 'value'], axis=1)\n",
        "edgelist_b.replace({'gameTitle' : games_dict}, inplace=True)\n",
        "edgelist_b.drop_duplicates(subset=['userID', 'gameTitle'], inplace=True)\n",
        "edgelist_b.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTsGYItr0uG9",
        "colab_type": "text"
      },
      "source": [
        "### Creating data validation for 10 users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiggwpifjVPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sampling users that have more than 15 purchases\n",
        "user_count = edgelist_b.groupby('userID').nunique()\n",
        "user_count.drop(user_count.columns[0], axis=1, inplace=True)\n",
        "user_count.reset_index(inplace=True)\n",
        "sample_user = user_count[user_count.gameTitle >= 20].sample(10)\n",
        "\n",
        "# Edge list for samples users\n",
        "temp_edge = edgelist_b[edgelist_b.userID.isin(sample_user.userID)]\n",
        "\n",
        "# Removing 10 observations for each userID in our list\n",
        "edge_10 = temp_edge.groupby('userID', group_keys=False, sort=False).apply(pd.DataFrame.tail, n=-10)\n",
        "\n",
        "# Removing sampled users from our original edgelist\n",
        "temp_edge2 = edgelist_b[~edgelist_b.userID.isin(sample_user.userID)]\n",
        "# Adding back the edgelist with 10 observations per user sampled removed\n",
        "edge_wo_10 = pd.concat([temp_edge2, edge_10], axis=0).reset_index(drop=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vVu1DA-qqYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating interactions with all games for our 10 validation users\n",
        "user_repeat = sample_user['userID'].repeat(len(games_list)).reset_index(drop=True)\n",
        "games_repeat = pd.concat([games_list]*10).reset_index(drop=True)\n",
        "\n",
        "games_repeat['userID'] = user_repeat\n",
        "games_repeat = games_repeat.reindex(columns=['userID', 'appid'])\n",
        "\n",
        "# Removing from the validation examples the observations that will go into the edgelist\n",
        "\n",
        "g_index = games_repeat.set_index(['userID', 'appid']).index\n",
        "edge_10_index = edge_10.set_index(['userID', 'gameTitle']).index\n",
        "\n",
        "mask = ~g_index.isin(edge_10_index)\n",
        "\n",
        "validation_examples = games_repeat[mask]\n",
        "\n",
        "# Creating labels\n",
        "\n",
        "obs_100 = pd.concat([temp_edge, edge_10]).drop_duplicates(keep=False)\n",
        "index_obs = obs_100.set_index(['userID', 'gameTitle']).index\n",
        "index_val = validation_examples.set_index(['userID', 'appid']).index\n",
        "\n",
        "validation_labels = index_val.isin(index_obs).astype(int)\n",
        "\n",
        "validation_examples = np.array(validation_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ57eSXqMK_B",
        "colab_type": "text"
      },
      "source": [
        "### Building model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBrktoI5MMBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building graph\n",
        "\n",
        "graph_b = sg.StellarGraph({'users': users_b, 'games': games_b}, \n",
        "                        {'play': edge_wo_10[['userID', 'gameTitle']]},\n",
        "                        source_column='userID',\n",
        "                        target_column='gameTitle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqIWnFa3MaOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "7cd5b323-002a-449c-ab5c-9e3d8809f385"
      },
      "source": [
        "# Splitting train/test\n",
        "\n",
        "# Test set\n",
        "edge_splitter_test = EdgeSplitter(graph_b)\n",
        "graph_test, examples_test, labels_test = edge_splitter_test.train_test_split(p=0.05, method=\"global\", edge_label='play')\n",
        "\n",
        "# Training set\n",
        "edge_splitter_train = EdgeSplitter(graph_test, graph_b)\n",
        "graph_train, examples, labels = edge_splitter_train.train_test_split(p=0.05, method=\"global\", edge_label='play')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network has 83194 edges of type play\n",
            "Removed 1000 edges\n",
            "Removed 2000 edges\n",
            "Removed 3000 edges\n",
            "Removed 4000 edges\n",
            "Network has 83194 edges of type play\n",
            "Sampled 1000 negative edges\n",
            "Sampled 2000 negative edges\n",
            "Sampled 3000 negative edges\n",
            "Sampled 4000 negative edges\n",
            "** Sampled 4159 positive and 4159 negative edges. **\n",
            "Network has 79035 edges of type play\n",
            "Removed 1000 edges\n",
            "Removed 2000 edges\n",
            "Removed 3000 edges\n",
            "Network has 79035 edges of type play\n",
            "Sampled 1000 negative edges\n",
            "Sampled 2000 negative edges\n",
            "Sampled 3000 negative edges\n",
            "** Sampled 3951 positive and 3951 negative edges. **\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqOfIwf7Pu_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67800455-4969-4868-950b-a1a99f3c6106"
      },
      "source": [
        "# Parameters\n",
        "\n",
        "batch_size_b = 50\n",
        "epochs_b = 20\n",
        "num_samples_b = [8,8,4,4]\n",
        "hinsage_layer_b = [256,256,256,256]\n",
        "num_workers_b = multiprocessing.cpu_count()\n",
        "\n",
        "# Training generator and flow\n",
        "generator_train_b = HinSAGELinkGenerator(graph_train, batch_size_b, num_samples_b, head_node_types=['games', 'users'])\n",
        "train_flow_b = generator_train_b.flow(examples, labels, shuffle=True)\n",
        "\n",
        "# test generator and flow\n",
        "test_gen_b = HinSAGELinkGenerator(graph_test, batch_size_b, num_samples_b, head_node_types=['games', 'users'])\n",
        "test_flow_b = test_gen_b.flow(examples_test, labels_test)\n",
        "\n",
        "# valid generator and flow\n",
        "valid_gen_b = HinSAGELinkGenerator(graph_b, batch_size_b, num_samples_b, head_node_types=['users', 'games'])\n",
        "valid_flow_b = valid_gen_b.flow(validation_examples, validation_labels)\n",
        "\n",
        "hinsage_b = HinSAGE(layer_sizes=hinsage_layer_b, generator=generator_train_b, bias=True, dropout=0.3)\n",
        "\n",
        "x_inb, x_outb = hinsage_b.in_out_tensors()\n",
        "pred_b = link_classification(output_dim=1, output_act=\"relu\", edge_embedding_method=\"ip\")(x_outb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "link_classification: using 'ip' method to combine node embeddings into edge embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cnUPN6LUmCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model\n",
        "\n",
        "model_b = Model(inputs=x_inb, outputs=pred_b)\n",
        "\n",
        "model_b.compile(\n",
        "    optimizer=optimizers.Adam(lr=1e-3),\n",
        "    loss=losses.binary_crossentropy,\n",
        "    metrics=[\"acc\", metrics.Precision()],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SxAJJ-8VDod",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "67df51cc-a808-4f47-9fb0-f28ef509f201"
      },
      "source": [
        "history_b = model_b.fit(\n",
        "    train_flow_b,\n",
        "    validation_data=test_flow_b,\n",
        "    epochs=epochs_b,\n",
        "    verbose=1,\n",
        "    shuffle=False,\n",
        "    use_multiprocessing=False,\n",
        "    workers=num_workers_b,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "159/159 [==============================] - ETA: 0s - loss: 0.4635 - acc: 0.8004 - precision: 0.7842"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw2ru5oFZvMq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb7bb797-5acd-4e2e-a204-e4b2f5ef61df"
      },
      "source": [
        "# Predict on test set\n",
        "\n",
        "#y_pred = model_b.predict(valid_flow_b, batch_size=batch_size_b)\n",
        "y_eval = model_b.evaluate(valid_flow_b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1515/1515 [==============================] - 55s 36ms/step - loss: 0.8019 - acc: 0.5960 - precision_4: 0.0078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0KC7S5I_cgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_final = pd.concat([pd.DataFrame(validation_examples), pd.DataFrame(y_pred)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTCANFVZ_fXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_final.columns = ['userID', 'gameID', 'prob']\n",
        "\n",
        "pred_f = predictions_final.groupby('userID').apply(pd.DataFrame.sort_values, 'prob', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr3ROhet3eMg",
        "colab_type": "text"
      },
      "source": [
        "# Model 3 - Node2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_oRO6Ph3sbc",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation (same as model 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvRH_YUH3ghT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keeping only purchases\n",
        "\n",
        "temp_ub = userst[userst.behavior == 'purchase']\n",
        "\n",
        "# Building user dataframe with retained users\n",
        "uniqueu_b = temp_ub.userID.unique()\n",
        "users_b =  users[users.userID.isin(uniqueu_b)]\n",
        "users_b.set_index('userID', inplace=True)\n",
        "\n",
        "# Building game dataframe with retained games\n",
        "uniqueg_b = temp_ub.gameTitle.unique()\n",
        "games_b = games[games.name.isin(uniqueg_b)]\n",
        "\n",
        "# Dropping columns we will not be using from games dataframe\n",
        "games_b.drop(['release_date', 'owners', 'name'], axis=1, inplace=True)\n",
        "games_b.set_index('appid', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5fniRQz3ndg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "15788b8d-ae0c-41ff-8b08-33be78b323ac"
      },
      "source": [
        "# Normalizing values\n",
        "users_b[['nPurchases', 'totalPlaytime']] = scaler.fit_transform(users_b[['nPurchases', 'totalPlaytime']])\n",
        "games_b[['positive_ratings', 'negative_ratings', 'average_playtime', 'median_playtime', 'price', 'year', 'month', 'required_age', 'achievements']] = scaler.fit_transform(games_b[['positive_ratings', 'negative_ratings', 'average_playtime', 'median_playtime', 'price', 'year', 'month', 'required_age', 'achievements']])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:2969: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:2935: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_array(key, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MDMNJxf3qHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building edgelist\n",
        "edgelist_b = temp_ub.reset_index().drop(['behavior', 'index', 'value'], axis=1)\n",
        "edgelist_b.replace({'gameTitle' : games_dict}, inplace=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKe1tjbS3wME",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqbLqInG3xKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building graph\n",
        "\n",
        "graph_b = sg.StellarGraph({'users': users_b, 'games': games_b}, \n",
        "                        {'play': edge_wo_10[['userID', 'gameTitle']]},\n",
        "                        source_column='userID',\n",
        "                        target_column='gameTitle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7aJVmT_3zm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "717ce079-29e1-4e6a-8a1b-3ccd7f065004"
      },
      "source": [
        "# Splitting train/test\n",
        "\n",
        "# Test set\n",
        "edge_splitter_test = EdgeSplitter(graph_b)\n",
        "graph_test, examples_test, labels_test = edge_splitter_test.train_test_split(p=0.05, method=\"global\", edge_label='play')\n",
        "\n",
        "# Train set\n",
        "edge_splitter_train = EdgeSplitter(graph_test, graph_b)\n",
        "graph_train, examples, labels = edge_splitter_train.train_test_split(p=0.05, method=\"global\", edge_label='play')\n",
        "\n",
        "(\n",
        "    examples_train,\n",
        "    examples_model_selection,\n",
        "    labels_train,\n",
        "    labels_model_selection,\n",
        ") = train_test_split(examples, labels, train_size=0.75, test_size=0.25)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network has 83733 edges of type play\n",
            "Removed 1000 edges\n",
            "Removed 2000 edges\n",
            "Removed 3000 edges\n",
            "Removed 4000 edges\n",
            "Network has 83733 edges of type play\n",
            "Sampled 1000 negative edges\n",
            "Sampled 2000 negative edges\n",
            "Sampled 3000 negative edges\n",
            "Sampled 4000 negative edges\n",
            "** Sampled 4186 positive and 4186 negative edges. **\n",
            "Network has 79547 edges of type play\n",
            "Removed 1000 edges\n",
            "Removed 2000 edges\n",
            "Removed 3000 edges\n",
            "Network has 79547 edges of type play\n",
            "Sampled 1000 negative edges\n",
            "Sampled 2000 negative edges\n",
            "Sampled 3000 negative edges\n",
            "** Sampled 3977 positive and 3977 negative edges. **\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KsoocAc331i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters \n",
        "\n",
        "p = 1.0\n",
        "q = 1.0\n",
        "dimensions = 128\n",
        "num_walks = 10\n",
        "walk_length = 80\n",
        "window_size = 10\n",
        "num_iter_n2 = 1\n",
        "workers_n2 = multiprocessing.cpu_count()\n",
        "\n",
        "def node2vec_embedding(graph, name):\n",
        "    rw = BiasedRandomWalk(graph)\n",
        "    walks = rw.run(graph.nodes(), n=num_walks, length=walk_length, p=p, q=q)\n",
        "    print(f\"Number of random walks for '{name}': {len(walks)}\")\n",
        "\n",
        "    model = Word2Vec(\n",
        "        walks,\n",
        "        size=dimensions,\n",
        "        window=window_size,\n",
        "        min_count=0,\n",
        "        sg=1,\n",
        "        workers=workers_n2,\n",
        "        iter=num_iter_n2,\n",
        "    )\n",
        "\n",
        "    def get_embedding(u):\n",
        "        return model.wv[u]\n",
        "\n",
        "    return get_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz2Apx6Z4aDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5dcf0a0c-57ff-47f4-e3b7-5f10387a22ad"
      },
      "source": [
        "embed_train = node2vec_embedding(graph_train, \"Train Graph\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of random walks for 'Train Graph': 144260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lskPzZYF5MS4",
        "colab_type": "text"
      },
      "source": [
        "### Function definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ1XN61-4bwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def link_examples_to_features(link_examples, transform_node, binary_operator):\n",
        "    return [\n",
        "        binary_operator(transform_node(src), transform_node(dst))\n",
        "        for src, dst in link_examples\n",
        "    ]\n",
        "\n",
        "\n",
        "# 2. training classifier\n",
        "def train_link_prediction_model(\n",
        "    link_examples, link_labels, get_embedding, binary_operator\n",
        "):\n",
        "    clf = link_prediction_classifier()\n",
        "    link_features = link_examples_to_features(\n",
        "        link_examples, get_embedding, binary_operator\n",
        "    )\n",
        "    clf.fit(link_features, link_labels)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def link_prediction_classifier(max_iter=2000):\n",
        "    lr_clf = LogisticRegressionCV(Cs=10, cv=10, scoring=\"roc_auc\", max_iter=max_iter)\n",
        "    return Pipeline(steps=[(\"sc\", preprocessing.StandardScaler()), (\"clf\", lr_clf)])\n",
        "\n",
        "\n",
        "# 3. and 4. evaluate classifier\n",
        "def evaluate_link_prediction_model(\n",
        "    clf, link_examples_test, link_labels_test, get_embedding, binary_operator\n",
        "):\n",
        "    link_features_test = link_examples_to_features(\n",
        "        link_examples_test, get_embedding, binary_operator\n",
        "    )\n",
        "    score = evaluate_average_precision(clf, link_features_test, link_labels_test)\n",
        "    return score\n",
        "\n",
        "\n",
        "def evaluate_roc_auc(clf, link_features, link_labels):\n",
        "    predicted = clf.predict_proba(link_features)\n",
        "\n",
        "    # check which class corresponds to positive links\n",
        "    positive_column = list(clf.classes_).index(1)\n",
        "    return roc_auc_score(link_labels, predicted[:, positive_column])\n",
        "\n",
        "    \n",
        "def evaluate_average_precision(clf, link_features, link_labels):\n",
        "    predicted = clf.predict_proba(link_features)\n",
        "\n",
        "    # check which class corresponds to positive links\n",
        "    positive_column = list(clf.classes_).index(1)\n",
        "    return average_precision_score(link_labels, predicted[:, positive_column])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI25Q7t85Jjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def operator_hadamard(u, v):\n",
        "    return u * v\n",
        "\n",
        "\n",
        "def operator_l1(u, v):\n",
        "    return np.abs(u - v)\n",
        "\n",
        "\n",
        "def operator_l2(u, v):\n",
        "    return (u - v) ** 2\n",
        "\n",
        "\n",
        "def operator_avg(u, v):\n",
        "    return (u + v) / 2.0\n",
        "\n",
        "\n",
        "def run_link_prediction(binary_operator):\n",
        "    clf = train_link_prediction_model(\n",
        "        examples, labels, embed_train, binary_operator\n",
        "    )\n",
        "    score = evaluate_link_prediction_model(\n",
        "        clf,\n",
        "        examples_model_selection,\n",
        "        labels_model_selection,\n",
        "        embed_train,\n",
        "        binary_operator,\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"classifier\": clf,\n",
        "        \"binary_operator\": binary_operator,\n",
        "        \"score\": score,\n",
        "    }\n",
        "\n",
        "binary_operators = [operator_hadamard, operator_l1, operator_l2, operator_avg]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m-BLQ5k5Pbd",
        "colab_type": "text"
      },
      "source": [
        "## Model training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls_wfuzo5OlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "results = [run_link_prediction(op) for op in binary_operators]\n",
        "best_result = max(results, key=lambda result: result[\"score\"])\n",
        "\n",
        "print(f\"Best result from '{best_result['binary_operator'].__name__}'\")\n",
        "\n",
        "pd.DataFrame(\n",
        "    [(result[\"binary_operator\"].__name__, result[\"score\"]) for result in results],\n",
        "    columns=(\"name\", \"Average Precision Score\"),\n",
        ").set_index(\"name\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipgYFOuMJEr0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d494ab7d-e076-4f7a-84de-35f9ab1bbca1"
      },
      "source": [
        "embedding_test = node2vec_embedding(graph_test, \"Test Graph\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of random walks for 'Test Graph': 144260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-e8ye5Z2vBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fec9ad4-b585-4888-f06c-6a8bb0f4bc87"
      },
      "source": [
        "embedding_valid = node2vec_embedding(graph_b, \"Valid Graph\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of random walks for 'Valid Graph': 144260\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}